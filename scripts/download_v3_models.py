#!/usr/bin/env python3
"""
V3 æ¨¡å‹æƒé‡ä¸‹è½½è„šæœ¬
==================
ä¸€é”®ä¸‹è½½ V3 çº¯è¯­ä¹‰æ—¶é—´å›¾å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿæ‰€éœ€çš„å…¨éƒ¨æ¨¡å‹æƒé‡ã€‚

æ¨¡å‹åˆ—è¡¨:
  1. Qwen2-VL-7B-Instruct  (~14 GB)  â€” ä¸» VLLM æ„ŸçŸ¥æ¨¡å‹
  2. Moondream2             (~3.6 GB) â€” è½»é‡çº§å¤‡é€‰ VLLM
  3. all-MiniLM-L6-v2       (~80 MB)  â€” Sentence-BERT è¯­ä¹‰ Re-ID

æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ç¼“å­˜åˆ°: <PROJECT_ROOT>/models/huggingface/

ç”¨æ³•:
  conda activate eventvad_vllm
  python scripts/download_v3_models.py              # ä¸‹è½½å…¨éƒ¨
  python scripts/download_v3_models.py --only qwen  # åªä¸‹è½½ Qwen2-VL
  python scripts/download_v3_models.py --only moon   # åªä¸‹è½½ Moondream2
  python scripts/download_v3_models.py --only sbert  # åªä¸‹è½½ Sentence-BERT
  python scripts/download_v3_models.py --exclude moon # æ’é™¤ Moondream2
"""

import os
import sys
import argparse
import pathlib
import time

# â”€â”€ è·¯å¾„è®¾ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = pathlib.Path(__file__).resolve().parents[1]  # EventVAD/
MODELS_DIR = PROJECT_ROOT / "models"
HF_CACHE_DIR = MODELS_DIR / "huggingface"
SBERT_CACHE_DIR = HF_CACHE_DIR / "sbert"

# è®¾ç½® HuggingFace ç¼“å­˜ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨ import transformers ä¹‹å‰ï¼‰
os.environ["HF_HOME"] = str(HF_CACHE_DIR)
os.environ["HUGGINGFACE_HUB_CACHE"] = str(HF_CACHE_DIR / "hub")

# â”€â”€ æ¨¡å‹å®šä¹‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = {
    "qwen": {
        "name": "Qwen2-VL-7B-Instruct",
        "repo_id": "Qwen/Qwen2-VL-7B-Instruct",
        "size": "~14 GB",
        "type": "transformers",
    },
    "moon": {
        "name": "Moondream2",
        "repo_id": "vikhyatk/moondream2",
        "size": "~3.6 GB",
        "type": "transformers",
    },
    "sbert": {
        "name": "all-MiniLM-L6-v2 (Sentence-BERT)",
        "repo_id": "sentence-transformers/all-MiniLM-L6-v2",
        "size": "~80 MB",
        "type": "sentence-transformers",
    },
}


def print_header():
    print("=" * 60)
    print("  EventVAD V3 â€” æ¨¡å‹æƒé‡ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print(f"  é¡¹ç›®æ ¹ç›®å½•:   {PROJECT_ROOT}")
    print(f"  æ¨¡å‹ç¼“å­˜ç›®å½•: {HF_CACHE_DIR}")
    print(f"  SBERT ç›®å½•:   {SBERT_CACHE_DIR}")
    print("=" * 60)


def download_transformers_model(repo_id: str, model_name: str):
    """é€šè¿‡ huggingface_hub ä¸‹è½½ transformers æ¨¡å‹"""
    from huggingface_hub import snapshot_download

    print(f"\n{'â”€' * 50}")
    print(f"  æ­£åœ¨ä¸‹è½½: {model_name}")
    print(f"  ä»“åº“:     {repo_id}")
    print(f"  ç›®æ ‡:     {HF_CACHE_DIR / 'hub'}")
    print(f"{'â”€' * 50}")

    t0 = time.time()
    local_path = snapshot_download(
        repo_id=repo_id,
        cache_dir=str(HF_CACHE_DIR / "hub"),
        resume_download=True,
    )
    elapsed = time.time() - t0

    print(f"  âœ… {model_name} ä¸‹è½½å®Œæˆ!")
    print(f"  ğŸ“ è·¯å¾„: {local_path}")
    print(f"  â±ï¸  è€—æ—¶: {elapsed:.1f}s")
    return local_path


def download_sbert_model(repo_id: str, model_name: str):
    """é€šè¿‡ sentence-transformers ä¸‹è½½ SBERT æ¨¡å‹"""
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError:
        print("  âš ï¸  sentence-transformers æœªå®‰è£…ï¼Œå°è¯•ç”¨ huggingface_hub ä¸‹è½½...")
        return download_transformers_model(repo_id, model_name)

    print(f"\n{'â”€' * 50}")
    print(f"  æ­£åœ¨ä¸‹è½½: {model_name}")
    print(f"  ä»“åº“:     {repo_id}")
    print(f"  ç›®æ ‡:     {SBERT_CACHE_DIR}")
    print(f"{'â”€' * 50}")

    t0 = time.time()
    model = SentenceTransformer(
        "all-MiniLM-L6-v2",
        cache_folder=str(SBERT_CACHE_DIR),
    )
    elapsed = time.time() - t0

    # éªŒè¯æ¨¡å‹å¯ç”¨
    test_emb = model.encode(["test sentence"])
    assert test_emb.shape[1] > 0, "SBERT æ¨¡å‹åŠ è½½éªŒè¯å¤±è´¥"

    print(f"  âœ… {model_name} ä¸‹è½½å®Œæˆ!")
    print(f"  ğŸ“ è·¯å¾„: {SBERT_CACHE_DIR}")
    print(f"  ğŸ“ å‘é‡ç»´åº¦: {test_emb.shape[1]}")
    print(f"  â±ï¸  è€—æ—¶: {elapsed:.1f}s")

    del model
    return str(SBERT_CACHE_DIR)


def verify_transformers_model(repo_id: str, model_name: str):
    """éªŒè¯ transformers æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜"""
    from huggingface_hub import try_to_load_from_cache, scan_cache_dir

    cache_info = scan_cache_dir(str(HF_CACHE_DIR / "hub"))
    for repo in cache_info.repos:
        if repo.repo_id == repo_id:
            size_gb = repo.size_on_disk / (1024 ** 3)
            print(f"  âœ… {model_name}: å·²ç¼“å­˜ ({size_gb:.2f} GB)")
            return True
    print(f"  âŒ {model_name}: æœªæ‰¾åˆ°ç¼“å­˜")
    return False


def verify_sbert_model():
    """éªŒè¯ SBERT æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜"""
    sbert_dir = SBERT_CACHE_DIR
    if sbert_dir.exists() and any(sbert_dir.iterdir()):
        total = sum(f.stat().st_size for f in sbert_dir.rglob("*") if f.is_file())
        size_mb = total / (1024 ** 2)
        print(f"  âœ… Sentence-BERT: å·²ç¼“å­˜ ({size_mb:.1f} MB)")
        return True
    print(f"  âŒ Sentence-BERT: æœªæ‰¾åˆ°ç¼“å­˜")
    return False


def main():
    parser = argparse.ArgumentParser(
        description="V3 æ¨¡å‹æƒé‡ä¸‹è½½å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python scripts/download_v3_models.py              # ä¸‹è½½å…¨éƒ¨
  python scripts/download_v3_models.py --only qwen  # åªä¸‹è½½ Qwen2-VL
  python scripts/download_v3_models.py --only sbert  # åªä¸‹è½½ SBERT
  python scripts/download_v3_models.py --exclude moon # æ’é™¤ Moondream2
  python scripts/download_v3_models.py --check       # ä»…æ£€æŸ¥ç¼“å­˜çŠ¶æ€
        """,
    )
    parser.add_argument(
        "--only",
        nargs="+",
        choices=list(MODELS.keys()),
        help="åªä¸‹è½½æŒ‡å®šæ¨¡å‹ (qwen, moon, sbert)",
    )
    parser.add_argument(
        "--exclude",
        nargs="+",
        choices=list(MODELS.keys()),
        help="æ’é™¤æŒ‡å®šæ¨¡å‹",
    )
    parser.add_argument(
        "--check",
        action="store_true",
        help="ä»…æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€ï¼Œä¸ä¸‹è½½",
    )
    args = parser.parse_args()

    print_header()

    # ç¡®å®šè¦å¤„ç†çš„æ¨¡å‹
    if args.only:
        target_keys = args.only
    else:
        target_keys = list(MODELS.keys())

    if args.exclude:
        target_keys = [k for k in target_keys if k not in args.exclude]

    if not target_keys:
        print("\n  âš ï¸  æ²¡æœ‰éœ€è¦å¤„ç†çš„æ¨¡å‹ï¼Œé€€å‡ºã€‚")
        return

    targets = {k: MODELS[k] for k in target_keys}

    # æ˜¾ç¤ºè®¡åˆ’
    print("\nğŸ“‹ è®¡åˆ’å¤„ç†çš„æ¨¡å‹:")
    for key, info in targets.items():
        print(f"   â€¢ {info['name']}  ({info['size']})")

    # ä»…æ£€æŸ¥æ¨¡å¼
    if args.check:
        print("\nğŸ” æ£€æŸ¥ç¼“å­˜çŠ¶æ€:")
        for key, info in targets.items():
            if info["type"] == "sentence-transformers":
                verify_sbert_model()
            else:
                try:
                    verify_transformers_model(info["repo_id"], info["name"])
                except Exception as e:
                    print(f"  âŒ {info['name']}: æ£€æŸ¥å¤±è´¥ ({e})")
        return

    # åˆ›å»ºç¼“å­˜ç›®å½•
    HF_CACHE_DIR.mkdir(parents=True, exist_ok=True)
    SBERT_CACHE_DIR.mkdir(parents=True, exist_ok=True)

    # ä¸‹è½½
    print(f"\nğŸš€ å¼€å§‹ä¸‹è½½ ({len(targets)} ä¸ªæ¨¡å‹)...\n")

    success = []
    failed = []
    t_total = time.time()

    for key, info in targets.items():
        try:
            if info["type"] == "sentence-transformers":
                download_sbert_model(info["repo_id"], info["name"])
            else:
                download_transformers_model(info["repo_id"], info["name"])
            success.append(info["name"])
        except KeyboardInterrupt:
            print("\n\n  âš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œå·²ä¸‹è½½çš„éƒ¨åˆ†ä¸ä¼šä¸¢å¤±ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰ã€‚")
            sys.exit(1)
        except Exception as e:
            print(f"\n  âŒ {info['name']} ä¸‹è½½å¤±è´¥: {e}")
            failed.append((info["name"], str(e)))

    total_elapsed = time.time() - t_total

    # æ±‡æ€»
    print(f"\n{'=' * 60}")
    print(f"  ä¸‹è½½å®Œæˆ! æ€»è€—æ—¶: {total_elapsed:.1f}s")
    print(f"{'=' * 60}")
    if success:
        print(f"  âœ… æˆåŠŸ: {', '.join(success)}")
    if failed:
        print(f"  âŒ å¤±è´¥:")
        for name, err in failed:
            print(f"     â€¢ {name}: {err}")

    print(f"\nğŸ“ æ¨¡å‹ç¼“å­˜ä½ç½®:")
    print(f"   HuggingFace: {HF_CACHE_DIR / 'hub'}")
    print(f"   SBERT:       {SBERT_CACHE_DIR}")
    print()


if __name__ == "__main__":
    main()
