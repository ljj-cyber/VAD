"""
V5 Bad Case è‡ªåŠ¨åˆ†æè„šæœ¬

è¯»å–è¯„ä¼°ç»“æœ JSONï¼Œè‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„ bad case åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
  - ä¸ä¸Šä¸€æ¬¡è¿è¡Œçš„å¯¹æ¯”
  - FN / FP é€ä¾‹æ ¹å› åˆ†æ
  - TP è´¨é‡åˆ†æ (IoU)
  - ç±»åˆ«çº§åˆ†æ
  - æ”¹è¿›å»ºè®®ä¼˜å…ˆçº§æ’åº

ç”¨æ³•:
  python -m v5.analyze_bad_cases \
      --current /path/to/current/results_v5.json \
      --previous /path/to/previous/results_v5.json \
      --output /path/to/bad_case_analysis.json
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from collections import Counter, defaultdict

import numpy as np

logger = logging.getLogger(__name__)


def load_results(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def classify_root_cause(detail: dict) -> tuple[str, str]:
    """
    æ ¹æ®ç»“æœè¯¦æƒ…è‡ªåŠ¨åˆ†ç±»æ ¹å› ã€‚
    è¿”å› (root_cause_code, explanation)
    """
    entities = detail.get("stats", {}).get("entities", 0)
    triggers = detail.get("stats", {}).get("triggers", 0)
    entity_verdicts = detail.get("entity_verdicts", [])
    pred_anomaly = detail.get("pred_anomaly", False)
    gt_anomaly = detail.get("gt_anomaly", False)

    # â”€â”€ FN åˆ†ç±» â”€â”€
    if gt_anomaly and not pred_anomaly:
        if entities == 0:
            return "ZERO_ENTITY_DETECTION", (
                f"Motion Extractor æœªæ£€æµ‹åˆ°ä»»ä½•è¿åŠ¨åŒºåŸŸ (0 entities, 0 triggers)ã€‚"
                f"Pipeline ç›´æ¥è¾“å‡º NORMALï¼Œæ— æ³•æŒ½å›ã€‚"
            )
        if triggers == 0:
            return "ZERO_TRIGGERS", (
                f"æ£€æµ‹åˆ° {entities} ä¸ªå®ä½“ä½† 0 ä¸ªè§¦å‘å™¨ã€‚NodeTrigger æœªè¢«æ¿€æ´»ã€‚"
            )

        # æœ‰å®ä½“å’Œè§¦å‘ï¼Œä½†æ‰€æœ‰å®ä½“åˆ¤æ­£å¸¸
        all_normal = all(not v.get("is_anomaly", False) for v in entity_verdicts)
        if all_normal:
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ danger_score éƒ½å¾ˆä½
            max_danger = 0.0
            for d in detail.get("entity_verdicts", []):
                # entity_verdicts ä¸ç›´æ¥å« danger_scoreï¼Œéœ€ä» verdict æ¨æ–­
                pass

            return "VLLM_UNDER_DESCRIPTION", (
                f"æ£€æµ‹åˆ° {entities} ä¸ªå®ä½“ã€{triggers} ä¸ªè§¦å‘å™¨ï¼Œ"
                f"ä½†æ‰€æœ‰å®ä½“å‡è¢«åˆ¤ä¸ºæ­£å¸¸ã€‚VLLM è¯­ä¹‰æè¿°æœªè¯†åˆ«å¼‚å¸¸è¡Œä¸ºã€‚"
            )

        return "DECISION_ERROR", (
            f"æ£€æµ‹åˆ°å¼‚å¸¸å®ä½“ä½†æœ€ç»ˆå†³ç­–æœªè¾“å‡ºå¼‚å¸¸ã€‚"
        )

    # â”€â”€ FP åˆ†ç±» â”€â”€
    if not gt_anomaly and pred_anomaly:
        anomaly_entities = [v for v in entity_verdicts if v.get("is_anomaly", False)]
        reasons = [v.get("reason", "") for v in anomaly_entities]
        reason_text = " | ".join(reasons)

        has_discordance = any(
            "motion energy" in r.lower() or "discordance" in r.lower()
            or "blind spot" in r.lower() or "threshold" in r.lower()
            for r in reasons
        )
        has_semantic = any(
            "fire" in r.lower() or "weapon" in r.lower()
            or "aggressive" in r.lower() or "pushing" in r.lower()
            or "fighting" in r.lower() or "confrontational" in r.lower()
            or "cash register" in r.lower() or "interaction" in r.lower()
            for r in reasons
        )

        if has_discordance and not has_semantic:
            return "DISCORDANCE_FALSE_ALARM", (
                f"Discordance æœºåˆ¶è¯¯è§¦å‘ã€‚"
                f"{len(anomaly_entities)} ä¸ªå®ä½“å› ç‰©ç†åŠ¨èƒ½è¶…æ ‡è¢«åˆ¤å¼‚å¸¸ï¼Œ"
                f"ä½† VLLM è¯­ä¹‰æ­£ç¡®è¯†åˆ«ä¸ºæ­£å¸¸æ´»åŠ¨ã€‚"
            )
        elif has_semantic:
            return "VLLM_HALLUCINATION", (
                f"VLLM è¯­ä¹‰æè¿°äº§ç”Ÿå¹»è§‰æˆ–è¿‡åº¦è§£è¯»ã€‚"
                f"{len(anomaly_entities)} ä¸ªå®ä½“åŸºäºè¯­ä¹‰å†…å®¹è¢«åˆ¤å¼‚å¸¸ã€‚"
                f"ç†ç”±: {reason_text[:200]}"
            )
        else:
            return "DECISION_FALSE_ALARM", (
                f"{len(anomaly_entities)} ä¸ªå®ä½“è¢«åˆ¤å¼‚å¸¸ï¼Œå¯¼è‡´æ­£å¸¸è§†é¢‘è¯¯æŠ¥ã€‚"
                f"ç†ç”±: {reason_text[:200]}"
            )

    return "OK", ""


def analyze_single_video(detail: dict) -> dict:
    """åˆ†æå•ä¸ªè§†é¢‘çš„è¯„ä¼°ç»“æœ"""
    filename = detail.get("filename", "unknown")
    category = detail.get("category", "Unknown")
    gt_anomaly = detail.get("gt_anomaly", False)
    pred_anomaly = detail.get("pred_anomaly", False)
    pred_score = detail.get("pred_score", 0.0)
    entity_verdicts = detail.get("entity_verdicts", [])
    stats = detail.get("stats", {})
    iou_soft = detail.get("iou_soft")
    iou_hyst = detail.get("iou_hysteresis")
    time_sec = detail.get("time_sec", 0)
    total_frames = detail.get("total_frames", 0)
    fps = detail.get("fps", 30.0)

    # åˆ†ç±»ç»“æœ
    if gt_anomaly and pred_anomaly:
        result_type = "TP"
    elif gt_anomaly and not pred_anomaly:
        result_type = "FN"
    elif not gt_anomaly and pred_anomaly:
        result_type = "FP"
    else:
        result_type = "TN"

    root_cause, explanation = classify_root_cause(detail)

    anomaly_entities = [v for v in entity_verdicts if v.get("is_anomaly", False)]
    normal_entities = [v for v in entity_verdicts if not v.get("is_anomaly", False)]

    result = {
        "filename": filename,
        "category": category,
        "result_type": result_type,
        "gt_anomaly": gt_anomaly,
        "pred_anomaly": pred_anomaly,
        "pred_score": pred_score,
        "entities": stats.get("entities", 0),
        "triggers": stats.get("triggers", 0),
        "nodes": stats.get("nodes", 0),
        "edges": stats.get("edges", 0),
        "total_frames": total_frames,
        "duration_sec": round(total_frames / max(fps, 1), 1),
        "processing_time_sec": time_sec,
    }

    if iou_soft is not None:
        result["iou_soft"] = round(iou_soft, 4)
    if iou_hyst is not None:
        result["iou_hysteresis"] = round(iou_hyst, 4)

    if result_type in ("FN", "FP"):
        result["root_cause"] = root_cause
        result["detail"] = explanation
        result["anomaly_entities"] = [
            {
                "entity_id": v.get("entity_id"),
                "is_anomaly": v.get("is_anomaly"),
                "confidence": v.get("confidence"),
                "reason": v.get("reason", "")[:200],
                "anomaly_start_sec": v.get("anomaly_start_sec", 0),
                "anomaly_end_sec": v.get("anomaly_end_sec", 0),
            }
            for v in anomaly_entities
        ]
        result["normal_entities_summary"] = [
            {
                "entity_id": v.get("entity_id"),
                "confidence": v.get("confidence"),
                "reason": v.get("reason", "")[:100],
            }
            for v in normal_entities[:5]  # åªå–å‰5ä¸ªèŠ‚çœç©ºé—´
        ]

    if result_type == "TP":
        result["anomaly_entities"] = [
            {
                "entity_id": v.get("entity_id"),
                "confidence": v.get("confidence"),
                "reason": v.get("reason", "")[:200],
                "anomaly_start_sec": v.get("anomaly_start_sec", 0),
                "anomaly_end_sec": v.get("anomaly_end_sec", 0),
            }
            for v in anomaly_entities
        ]

    return result


def compare_runs(current_details: list, previous_details: list) -> dict:
    """å¯¹æ¯”ä¸¤æ¬¡è¿è¡Œç»“æœ"""
    prev_map = {d["filename"]: d for d in previous_details}
    curr_map = {d["filename"]: d for d in current_details}

    flips = []
    iou_changes = []

    for fname in curr_map:
        if fname not in prev_map:
            continue

        curr = curr_map[fname]
        prev = prev_map[fname]

        curr_correct = curr.get("pred_anomaly") == curr.get("gt_anomaly")
        prev_correct = prev.get("pred_anomaly") == prev.get("gt_anomaly")

        # åˆ†ç±»å˜åŒ–
        def _classify(d):
            if d["gt_anomaly"] and d["pred_anomaly"]:
                return "TP"
            elif d["gt_anomaly"] and not d["pred_anomaly"]:
                return "FN"
            elif not d["gt_anomaly"] and d["pred_anomaly"]:
                return "FP"
            else:
                return "TN"

        prev_type = _classify(prev)
        curr_type = _classify(curr)

        if prev_type != curr_type:
            improved = curr_correct and not prev_correct
            regressed = not curr_correct and prev_correct

            # è·å–å½“å‰ entity_verdicts çš„ç®€è¦ç†ç”±
            curr_reasons = []
            for v in curr.get("entity_verdicts", []):
                if v.get("is_anomaly"):
                    curr_reasons.append(
                        f"Entity #{v.get('entity_id')}: {v.get('reason', '')[:80]}"
                    )

            flips.append({
                "filename": fname,
                "change": f"{prev_type} â†’ {curr_type}" + (" âœ…" if improved else " âš ï¸" if regressed else ""),
                "improved": improved,
                "regressed": regressed,
                "entity_reasons": curr_reasons[:3],
            })

        # IoU å˜åŒ–
        curr_iou_s = curr.get("iou_soft")
        prev_iou_s = prev.get("iou_soft")
        if curr_iou_s is not None and prev_iou_s is not None:
            delta = curr_iou_s - prev_iou_s
            if abs(delta) > 0.02:
                iou_changes.append({
                    "filename": fname,
                    "old_iou": round(prev_iou_s, 4),
                    "new_iou": round(curr_iou_s, 4),
                    "delta": round(delta, 4),
                    "tag": "âœ…" if delta > 0 else "âš ï¸",
                })

    iou_changes.sort(key=lambda x: -abs(x["delta"]))

    return {
        "video_level_flips": flips,
        "iou_changes": iou_changes[:15],  # Top 15 biggest changes
    }


def build_root_cause_summary(analyses: list) -> dict:
    """æ±‡æ€»æ ¹å› åˆ†å¸ƒ"""
    rc_counter = Counter()
    rc_videos = defaultdict(list)

    for a in analyses:
        if a["result_type"] in ("FN", "FP"):
            rc = a.get("root_cause", "UNKNOWN")
            rc_counter[rc] += 1
            rc_videos[rc].append(a["filename"])

    summary = {}
    descriptions = {
        "ZERO_ENTITY_DETECTION": {
            "description": "Motion Extractor å®Œå…¨æœªæ£€æµ‹åˆ°è¿åŠ¨åŒºåŸŸ (0 entities)ã€‚Pipeline ç›´æ¥è¾“å‡º NORMALã€‚",
            "fix_suggestions": [
                "é™ä½ diff_threshold (å½“å‰25) â†’ å¯¹ä½å¯¹æ¯”åº¦åœºæ™¯ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼",
                "é™ä½ min_region_area (å½“å‰1500) â†’ å…è®¸æ›´å°çš„è¿åŠ¨åŒºåŸŸ",
                "æ·»åŠ åŸºäºå…‰æµçš„è¿åŠ¨æ£€æµ‹ä½œä¸ºå¸§å·®æ³•çš„è¡¥å……",
                "æ·»åŠ  fallback æœºåˆ¶ï¼šå½“ 0 entities æ—¶ç”¨å…¨å›¾è¿›è¡Œå…¨å±€è¯­ä¹‰åˆ†æ",
            ],
        },
        "ZERO_TRIGGERS": {
            "description": "æœ‰å®ä½“ä½†æ— è§¦å‘å™¨ã€‚NodeTrigger æ¡ä»¶æœªæ»¡è¶³ã€‚",
            "fix_suggestions": [
                "é™ä½ embedding_jump_threshold",
                "ç¼©çŸ­ heartbeat_interval_sec",
            ],
        },
        "VLLM_UNDER_DESCRIPTION": {
            "description": "VLLM è¯­ä¹‰æè¿°ä¸è¶³ï¼Œæœªè¯†åˆ«å…³é”®å¼‚å¸¸è¡Œä¸º (fire/fight/intrusion ç­‰)ã€‚",
            "fix_suggestions": [
                "ä¼˜åŒ– VLLM promptï¼Œå¼ºåˆ¶è¦æ±‚æè¿°: æ˜¯å¦æœ‰ç«ç„°/çƒŸé›¾/æ‰“æ–—/å…¥ä¾µè¡Œä¸º",
                "åœ¨ prompt ä¸­åŠ å…¥ 'Look carefully for fire, flames, smoke, fighting, trespassing'",
                "æ·»åŠ  CLIP zero-shot fire/smoke/fight ä¸“ç”¨æ£€æµ‹å™¨ä½œä¸ºè¾…åŠ©ä¿¡å·",
                "å¢å¤§ crop åŒºåŸŸæˆ–ä½¿ç”¨å¤šå°ºåº¦è¾“å…¥",
            ],
        },
        "DISCORDANCE_FALSE_ALARM": {
            "description": "Discordance æœºåˆ¶ (é«˜ç‰©ç†åŠ¨èƒ½ + ä½è¯­ä¹‰danger) åœ¨æ­£å¸¸é«˜è¿åŠ¨åœºæ™¯è¯¯è§¦å‘ã€‚",
            "fix_suggestions": [
                "æ·»åŠ å¤šå®ä½“ä¸€è‡´æ€§æŠ•ç¥¨: å½“ >70% å®ä½“åˆ¤æ­£å¸¸æ—¶ï¼Œå•ä¸ª discordance ä¸ç¿»è½¬æ•´ä½“",
                "æé«˜ discordance çš„åŠ¨èƒ½é˜ˆå€¼ (Î¼+3Ïƒ â†’ Î¼+4Ïƒ)",
                "é™ä½ discordance åˆ¤å®šçš„ confidence (0.90â†’0.60)",
                "ç»“åˆåœºæ™¯ç±»å‹: indoor/retail åœºæ™¯æ­£å¸¸åŠ¨èƒ½èŒƒå›´æ›´å¤§",
            ],
        },
        "VLLM_HALLUCINATION": {
            "description": "VLLM è¯­ä¹‰æè¿°äº§ç”Ÿå¹»è§‰æˆ–è¿‡åº¦è§£è¯»ï¼Œå°†æ­£å¸¸è¡Œä¸ºè¯¯åˆ¤ä¸ºå¼‚å¸¸ã€‚",
            "fix_suggestions": [
                "åœ¨ prompt ä¸­å¼ºè°ƒ 'Only flag truly dangerous or illegal behavior'",
                "æ·»åŠ å¤šè½®éªŒè¯: å¯¹ suspicious=True çš„ç»“æœè¿›è¡ŒäºŒæ¬¡ç¡®è®¤",
                "é™ä½å•æ¬¡è¯­ä¹‰åˆ¤å®šçš„æƒé‡",
            ],
        },
        "DECISION_FALSE_ALARM": {
            "description": "Decision å±‚å°†æ­£å¸¸è§†é¢‘è¯¯åˆ¤ä¸ºå¼‚å¸¸ã€‚",
            "fix_suggestions": [
                "æé«˜ anomaly_confidence_threshold",
                "æ·»åŠ å¤šå®ä½“æŠ•ç¥¨æœºåˆ¶",
            ],
        },
        "DECISION_ERROR": {
            "description": "æ£€æµ‹åˆ°å¼‚å¸¸ä¿¡å·ä½†æœ€ç»ˆå†³ç­–æœªè¾“å‡ºå¼‚å¸¸ã€‚",
            "fix_suggestions": [
                "æ£€æŸ¥ Decision Auditor é€»è¾‘",
                "é™ä½ anomaly_confidence_threshold",
            ],
        },
    }

    for rc, count in rc_counter.most_common():
        info = descriptions.get(rc, {"description": rc, "fix_suggestions": []})
        summary[rc] = {
            "count": count,
            "affected_videos": rc_videos[rc],
            "description": info["description"],
            "fix_suggestions": info["fix_suggestions"],
        }

    return summary


def build_category_analysis(analyses: list) -> dict:
    """æŒ‰ç±»åˆ«æ±‡æ€»åˆ†æ"""
    cats = defaultdict(lambda: {
        "total": 0, "correct": 0, "tp": 0, "fn": 0, "fp": 0, "tn": 0,
        "ious_soft": [], "ious_hyst": [],
        "fn_videos": [], "fp_videos": [],
    })

    for a in analyses:
        cat = a["category"]
        cats[cat]["total"] += 1
        is_correct = a["result_type"] in ("TP", "TN")
        if is_correct:
            cats[cat]["correct"] += 1
        cats[cat][a["result_type"].lower()] += 1

        if a.get("iou_soft") is not None and a["result_type"] == "TP":
            cats[cat]["ious_soft"].append(a["iou_soft"])
        if a.get("iou_hysteresis") is not None and a["result_type"] == "TP":
            cats[cat]["ious_hyst"].append(a["iou_hysteresis"])

        if a["result_type"] == "FN":
            cats[cat]["fn_videos"].append(a["filename"])
        if a["result_type"] == "FP":
            cats[cat]["fp_videos"].append(a["filename"])

    result = {}
    for cat in sorted(cats.keys()):
        s = cats[cat]
        result[cat] = {
            "total": s["total"],
            "correct": s["correct"],
            "accuracy": round(s["correct"] / s["total"], 4) if s["total"] > 0 else 0,
            "tp": s["tp"], "fn": s["fn"], "fp": s["fp"], "tn": s["tn"],
            "mean_iou_soft": round(float(np.mean(s["ious_soft"])), 4) if s["ious_soft"] else None,
            "mean_iou_hyst": round(float(np.mean(s["ious_hyst"])), 4) if s["ious_hyst"] else None,
            "fn_videos": s["fn_videos"],
            "fp_videos": s["fp_videos"],
        }

    return result


def build_iou_analysis(analyses: list) -> dict:
    """IoU è¯¦ç»†åˆ†æ"""
    tp_analyses = [a for a in analyses if a["result_type"] == "TP"]

    excellent = []
    moderate = []
    zero = []

    for a in tp_analyses:
        iou_s = a.get("iou_soft", 0)
        iou_h = a.get("iou_hysteresis", 0)
        best_iou = max(iou_s or 0, iou_h or 0)

        entry = {
            "filename": a["filename"],
            "category": a["category"],
            "iou_soft": iou_s,
            "iou_hysteresis": iou_h,
            "pred_score": a["pred_score"],
            "entities": a["entities"],
        }

        if best_iou >= 0.5:
            excellent.append(entry)
        elif best_iou > 0.05:
            moderate.append(entry)
        else:
            zero.append(entry)

    all_ious_soft = [a.get("iou_soft", 0) for a in tp_analyses if a.get("iou_soft") is not None]
    all_ious_hyst = [a.get("iou_hysteresis", 0) for a in tp_analyses if a.get("iou_hysteresis") is not None]

    return {
        "overall_mean_iou_soft": round(float(np.mean(all_ious_soft)), 4) if all_ious_soft else 0,
        "overall_mean_iou_hyst": round(float(np.mean(all_ious_hyst)), 4) if all_ious_hyst else 0,
        "excellent_iou_above_0.5": sorted(excellent, key=lambda x: -(x.get("iou_hysteresis") or 0)),
        "moderate_iou_0.05_to_0.5": sorted(moderate, key=lambda x: -(x.get("iou_hysteresis") or 0)),
        "near_zero_iou": zero,
        "total_tp": len(tp_analyses),
        "count_excellent": len(excellent),
        "count_moderate": len(moderate),
        "count_zero": len(zero),
    }


def build_priority_actions(
    root_causes: dict,
    category_analysis: dict,
    iou_analysis: dict,
    metrics: dict,
) -> list:
    """åŸºäºåˆ†æç»“æœè‡ªåŠ¨ç”Ÿæˆä¼˜å…ˆçº§è¡ŒåŠ¨å»ºè®®"""
    actions = []

    # P0: 0-entity é—®é¢˜
    if "ZERO_ENTITY_DETECTION" in root_causes:
        rc = root_causes["ZERO_ENTITY_DETECTION"]
        actions.append({
            "priority": "P0",
            "action": "ä¿®å¤ 0-entity æ£€æµ‹çš„ fallback æœºåˆ¶",
            "reason": f"{rc['count']} ä¸ªè§†é¢‘å›  0 entities å¿…ç„¶æ¼åˆ¤: {', '.join(rc['affected_videos'])}",
            "expected_impact": f"æ¶ˆé™¤ {rc['count']} ä¸ª FN, recall æå‡çº¦ +{rc['count']*5}%",
            "suggested_approach": rc["fix_suggestions"],
        })

    # P0: VLLM æè¿°ä¸è¶³
    if "VLLM_UNDER_DESCRIPTION" in root_causes:
        rc = root_causes["VLLM_UNDER_DESCRIPTION"]
        actions.append({
            "priority": "P0",
            "action": "å¢å¼º VLLM å¯¹å¼‚å¸¸è¡Œä¸ºçš„è¯†åˆ«èƒ½åŠ›",
            "reason": f"{rc['count']} ä¸ªè§†é¢‘å›  VLLM è¯­ä¹‰æè¿°ä¸è¶³è€Œæ¼åˆ¤: {', '.join(rc['affected_videos'])}",
            "expected_impact": f"æ¶ˆé™¤ {rc['count']}+ ä¸ª FN",
            "suggested_approach": rc["fix_suggestions"],
        })

    # P0: Discordance è¯¯æŠ¥
    if "DISCORDANCE_FALSE_ALARM" in root_causes:
        rc = root_causes["DISCORDANCE_FALSE_ALARM"]
        actions.append({
            "priority": "P0",
            "action": "ä¼˜åŒ– discordance æœºåˆ¶ï¼Œå‡å°‘æ­£å¸¸åœºæ™¯è¯¯æŠ¥",
            "reason": f"{rc['count']} ä¸ªæ­£å¸¸è§†é¢‘å›  discordance æœºåˆ¶è¯¯è§¦å‘: {', '.join(rc['affected_videos'])}",
            "expected_impact": f"FP å‡å°‘ {rc['count']}, Precision æå‡",
            "suggested_approach": rc["fix_suggestions"],
        })

    # P0: VLLM å¹»è§‰
    if "VLLM_HALLUCINATION" in root_causes:
        rc = root_causes["VLLM_HALLUCINATION"]
        actions.append({
            "priority": "P0",
            "action": "æŠ‘åˆ¶ VLLM è¯­ä¹‰å¹»è§‰",
            "reason": f"{rc['count']} ä¸ªè§†é¢‘å›  VLLM å¹»è§‰å¯¼è‡´ FP: {', '.join(rc['affected_videos'])}",
            "expected_impact": f"FP å‡å°‘ {rc['count']}",
            "suggested_approach": rc["fix_suggestions"],
        })

    # P1: IoU æ”¹å–„
    zero_iou_count = iou_analysis.get("count_zero", 0)
    if zero_iou_count > 0:
        actions.append({
            "priority": "P1",
            "action": "æ”¹å–„å¼‚å¸¸åŒºé—´å®šä½ç²¾åº¦ (IoU)",
            "reason": f"{zero_iou_count} ä¸ª TP è§†é¢‘ IoU æ¥è¿‘ 0ï¼Œè§†é¢‘çº§æ­£ç¡®ä½†æ—¶é—´å®šä½å®Œå…¨åç§»",
            "expected_impact": "Frame AUC æå‡, Mean IoU æå‡",
            "suggested_approach": [
                "å¢å¤§å¸§çº§åˆ†æ•°çš„æ—¶é—´æ‰©æ•£åŠå¾„ (Ïƒ=3s â†’ 5s)",
                "ä½¿ç”¨æ›´ç²¾ç¡®çš„ entity_verdict anomaly_start/end_sec",
                "å¯¹ discordance æ£€å‡ºçš„å¼‚å¸¸ï¼Œæ ¹æ®åŠ¨èƒ½å³°å€¼å®šä½æ—¶é—´åŒºé—´",
            ],
        })

    # P1: å¼±ç±»åˆ«
    for cat, info in category_analysis.items():
        if cat == "Normal":
            continue
        if info["accuracy"] < 0.5 and info["total"] > 0:
            actions.append({
                "priority": "P1",
                "action": f"å¢å¼º {cat} ç±»åˆ«æ£€æµ‹èƒ½åŠ›",
                "reason": f"{cat} accuracy={info['accuracy']:.2f} ({info['correct']}/{info['total']}), FN: {', '.join(info['fn_videos'])}",
                "expected_impact": f"{cat} recall æå‡",
                "suggested_approach": [
                    f"åˆ†æ {cat} FN çš„å…·ä½“åŸå› å¹¶é’ˆå¯¹æ€§ä¼˜åŒ–",
                    "åœ¨ prompt ä¸­å¢åŠ é’ˆå¯¹æ€§çš„æ£€æµ‹è¦æ±‚",
                ],
            })

    return actions


def generate_analysis(
    current_path: str,
    previous_path: str = None,
    output_path: str = None,
) -> dict:
    """ç”Ÿæˆå®Œæ•´çš„ bad case åˆ†ææŠ¥å‘Š"""
    current = load_results(current_path)
    current_metrics = current.get("metrics", {})
    current_details = current.get("details", [])

    # â”€â”€ é€è§†é¢‘åˆ†æ â”€â”€
    analyses = [analyze_single_video(d) for d in current_details]

    # åˆ†ç±»
    fn_list = [a for a in analyses if a["result_type"] == "FN"]
    fp_list = [a for a in analyses if a["result_type"] == "FP"]
    tp_list = [a for a in analyses if a["result_type"] == "TP"]
    tn_list = [a for a in analyses if a["result_type"] == "TN"]

    # â”€â”€ ä¸ä¸Šæ¬¡å¯¹æ¯” â”€â”€
    comparison = {}
    if previous_path:
        previous = load_results(previous_path)
        prev_metrics = previous.get("metrics", {})
        prev_details = previous.get("details", [])

        metric_keys = ["accuracy", "precision", "recall", "f1", "frame_auc",
                        "video_auc", "mean_iou_soft", "mean_iou_hysteresis"]
        metric_changes = {}
        for key in metric_keys:
            old_val = prev_metrics.get(key, 0)
            new_val = current_metrics.get(key, 0)
            delta = new_val - old_val
            tag = "âœ…" if delta > 0.005 else "âš ï¸" if delta < -0.005 else "â”"
            metric_changes[key] = {
                "old": round(old_val, 4),
                "new": round(new_val, 4),
                "delta": f"{delta:+.4f} {tag}",
            }

        cm_keys = ["tp", "fn", "fp", "tn"]
        cm_changes = {}
        for key in cm_keys:
            old_val = prev_metrics.get(key, 0)
            new_val = current_metrics.get(key, 0)
            delta = new_val - old_val
            tag = ""
            if key in ("tp", "tn"):
                tag = "âœ…" if delta > 0 else "âš ï¸" if delta < 0 else ""
            else:
                tag = "âœ…" if delta < 0 else "âš ï¸" if delta > 0 else ""
            cm_changes[key] = {"old": old_val, "new": new_val, "delta": f"{delta:+d} {tag}".strip()}

        run_comparison = compare_runs(current_details, prev_details)

        comparison = {
            "previous_run": previous_path,
            "current_run": current_path,
            "metric_changes": metric_changes,
            "confusion_matrix_changes": cm_changes,
            **run_comparison,
        }

    # â”€â”€ æ±‡æ€» â”€â”€
    root_causes = build_root_cause_summary(analyses)
    category_analysis = build_category_analysis(analyses)
    iou_analysis = build_iou_analysis(analyses)
    priority_actions = build_priority_actions(
        root_causes, category_analysis, iou_analysis, current_metrics
    )

    # â”€â”€ ç»„è£…æŠ¥å‘Š â”€â”€
    report = {
        "eval_summary": {
            "version": "v5",
            "run_dir": current_metrics.get("run_dir", ""),
            "run_timestamp": current_metrics.get("run_timestamp", ""),
            "total_videos": current_metrics.get("total", 0),
            "accuracy": current_metrics.get("accuracy", 0),
            "precision": current_metrics.get("precision", 0),
            "recall": current_metrics.get("recall", 0),
            "f1": current_metrics.get("f1", 0),
            "frame_auc": current_metrics.get("frame_auc", 0),
            "video_auc": current_metrics.get("video_auc", 0),
            "mean_iou_soft": current_metrics.get("mean_iou_soft", 0),
            "mean_iou_hysteresis": current_metrics.get("mean_iou_hysteresis", 0),
            "confusion_matrix": {
                "TP": current_metrics.get("tp", 0),
                "FN": current_metrics.get("fn", 0),
                "FP": current_metrics.get("fp", 0),
                "TN": current_metrics.get("tn", 0),
            },
        },
    }

    if comparison:
        report["comparison_with_previous_run"] = comparison

    report["false_negatives"] = sorted(fn_list, key=lambda x: x["category"])
    report["false_positives"] = fp_list
    report["true_positives_analysis"] = {
        "count": len(tp_list),
        "details": sorted(tp_list, key=lambda x: -(x.get("iou_hysteresis") or 0)),
    }
    report["true_negatives_count"] = len(tn_list)
    report["root_cause_summary"] = root_causes
    report["category_analysis"] = category_analysis
    report["iou_analysis"] = iou_analysis
    report["priority_action_items"] = priority_actions

    # â”€â”€ æ€»ä½“è¯„ä¼° â”€â”€
    recall = current_metrics.get("recall", 0)
    precision = current_metrics.get("precision", 0)
    strengths = []
    weaknesses = []

    for cat, info in category_analysis.items():
        if cat == "Normal":
            if info["accuracy"] < 0.9:
                weaknesses.append(f"Normal å‡†ç¡®ç‡ä»… {info['accuracy']:.2f} ({info['correct']}/{info['total']}), FP: {', '.join(info['fp_videos'])}")
            else:
                strengths.append(f"Normal å‡†ç¡®ç‡ {info['accuracy']:.2f} ({info['correct']}/{info['total']})")
        else:
            if info["accuracy"] >= 0.9:
                strengths.append(f"{cat} recall æ»¡åˆ† ({info['correct']}/{info['total']})")
            elif info["accuracy"] >= 0.7:
                strengths.append(f"{cat} recall {info['accuracy']:.2f} ({info['correct']}/{info['total']})")
            elif info["accuracy"] < 0.5 and info["total"] > 0:
                weaknesses.append(f"{cat} æ£€æµ‹å›°éš¾ ({info['correct']}/{info['total']}), FN: {', '.join(info['fn_videos'])}")

    if iou_analysis.get("count_zero", 0) > len(tp_list) * 0.3:
        weaknesses.append(f"{iou_analysis['count_zero']}/{len(tp_list)} ä¸ª TP è§†é¢‘ IoUâ‰ˆ0ï¼Œæ—¶é—´å®šä½å·®")

    report["overall_assessment"] = {
        "current_performance": (
            f"Accuracy={current_metrics.get('accuracy', 0):.4f}, "
            f"F1={current_metrics.get('f1', 0):.4f}, "
            f"Recall={recall:.4f}, "
            f"Precision={precision:.4f}, "
            f"Frame AUC={current_metrics.get('frame_auc', 0):.4f}, "
            f"Video AUC={current_metrics.get('video_auc', 0):.4f}"
        ),
        "key_strengths": strengths,
        "key_weaknesses": weaknesses,
    }

    # â”€â”€ ä¿å­˜ â”€â”€
    if output_path:
        out = Path(output_path)
        out.parent.mkdir(parents=True, exist_ok=True)
        with open(out, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        logger.info(f"Bad case analysis saved to {out}")

    return report


def main():
    parser = argparse.ArgumentParser(description="V5 Bad Case Analysis")
    parser.add_argument("--current", required=True, help="å½“å‰è¯„ä¼°ç»“æœ JSON è·¯å¾„")
    parser.add_argument("--previous", default=None, help="ä¸Šä¸€æ¬¡è¯„ä¼°ç»“æœ JSON è·¯å¾„ (å¯é€‰ï¼Œç”¨äºå¯¹æ¯”)")
    parser.add_argument("--output", default=None, help="è¾“å‡ºåˆ†ææŠ¥å‘Šè·¯å¾„")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

    if not args.output:
        # é»˜è®¤è¾“å‡ºåˆ°å½“å‰ç»“æœåŒç›®å½•
        args.output = str(Path(args.current).parent / "bad_case_analysis.json")

    report = generate_analysis(
        current_path=args.current,
        previous_path=args.previous,
        output_path=args.output,
    )

    # æ‰“å°æ‘˜è¦
    summary = report["eval_summary"]
    print(f"\n{'='*70}")
    print(f"  V5 Bad Case Analysis Report")
    print(f"{'='*70}")
    print(f"  Accuracy:  {summary['accuracy']:.4f}")
    print(f"  Precision: {summary['precision']:.4f}")
    print(f"  Recall:    {summary['recall']:.4f}")
    print(f"  F1:        {summary['f1']:.4f}")
    print(f"  Frame AUC: {summary['frame_auc']:.4f}")
    print(f"  Video AUC: {summary['video_auc']:.4f}")
    print(f"  TP={summary['confusion_matrix']['TP']} "
          f"FN={summary['confusion_matrix']['FN']} "
          f"FP={summary['confusion_matrix']['FP']} "
          f"TN={summary['confusion_matrix']['TN']}")
    print()

    # FN æ‘˜è¦
    fn = report.get("false_negatives", [])
    if fn:
        print(f"  âŒ False Negatives ({len(fn)}):")
        for item in fn:
            rc = item.get("root_cause", "UNKNOWN")
            print(f"    - {item['filename']} [{item['category']}] â†’ {rc}")
            print(f"      entities={item['entities']} triggers={item['triggers']}")
        print()

    # FP æ‘˜è¦
    fp = report.get("false_positives", [])
    if fp:
        print(f"  âš ï¸  False Positives ({len(fp)}):")
        for item in fp:
            rc = item.get("root_cause", "UNKNOWN")
            print(f"    - {item['filename']} [{item['category']}] â†’ {rc}")
            print(f"      score={item['pred_score']:.2f} entities={item['entities']}")
        print()

    # å¯¹æ¯”æ‘˜è¦
    comp = report.get("comparison_with_previous_run", {})
    if comp:
        flips = comp.get("video_level_flips", [])
        if flips:
            print(f"  ğŸ”„ Video-level Flips ({len(flips)}):")
            for flip in flips:
                print(f"    - {flip['filename']}: {flip['change']}")
            print()

    # ä¼˜å…ˆè¡ŒåŠ¨
    actions = report.get("priority_action_items", [])
    if actions:
        print(f"  ğŸ“‹ Priority Actions:")
        for a in actions:
            print(f"    [{a['priority']}] {a['action']}")
            print(f"         â†’ {a['reason'][:100]}")
        print()

    print(f"  Report saved to: {args.output}")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    main()
